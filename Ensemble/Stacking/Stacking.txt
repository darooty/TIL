Stacked Generalization 또는 줄여서 Stacking은 앙상블 기계 학습 알고리즘이다.
배깅 및 부스팅과 같은 동일한 데이터 세트에서 여러 머신러닝 모델의 예측을 결합하는 것이 포함된다.
Stacking은 다음과 같은 문제를 해결한다.

    - 문제에 능숙하지만 다양한 방식으로 여러 기계 학습 모델을 사용할 경우(신뢰할) 어떤 모델을 선택할 수 있습니까?

배깅과 달리 스태킹에서 모델은 일반적으로 다르며 동일한 데이터 세트에 적합한다.
부스팅과 달리 스태킹에서는 단일 모델이 기여하는 모델의 예측을 가장 잘 결합하는 방법을 학습하는 데 사용된다.
적층 모델의 아키텍처에는 종종 수준 0 모델이라고 하는 둘 이상의 기본 모델과 수준 1 모델이라고 하는 기본 모델의 예측을 결합하는
메타 모델이 포함된다.

레벨 0 모델(기본 모델): 모형은 교육 데이터에 적합하고 예측이 컴파일된다.
레벨-1 모델(메타-모델): 기본 모형의 예측을 가장 잘 결합하는 방법을 배우는 모형이다.
메타 모델은 표본 외 데이터에 대한 기본 모델의 예측에 대해 학습된다. 즉, 기본 모델을 훈련하는 데 사용되지 않은 데이터가 기본 모델에 공급되고
예측이 이루어지며, 이러한 예측은 예상 출력과 함께 메타 모델에 맞는 훈련 데이터 세트의 입력 및 출력 쌍을 제공한다.

메타 모델에 대한 입력으로 사용되는 기본 모델의 출력은 회귀의 경우 실제 값일 수 있으며,
분류의 경우 확률 값, 확률과 같은 값 또는 클래스 레이블일 수 있다.
메타 모델에 대한 교육 데이터 세트를 준비하는 가장 일반적인 접근 방식은 기본 모델의 k-폴드 교차 검증을 통해 수행되며, 여기서 아웃폴드 예측이
메타 모델에 대한 교육 데이터 세트의 기준으로 사용된다.
메타 모델에 대한 교육 데이터에는 기본 모델에 대한 입력(예: 교육 데이터의 입력 요소)도 포함될 수 있다. 
이렇게 하면 메타 모델의 예측을 최적으로 결합하는 방법에 대한 추가적인 컨텍스트를 메타 모델에 제공할 수 있다.

메타 모델에 대한 교육 데이터 세트가 준비되면 메타 모델을 이 데이터 세트에서 격리하여 교육할 수 있으며, 기본 모델은 전체 원래 교육 데이터
세트에서 교육할 수 있다.
스택킹은 다양한 머신러닝 모델이 데이터 세트에 대한 기술을 가지고 있지만 다양한 방식으로 기술을 보유하고 있을 때 적합하다. 
또 다른 방법은 모형에 의한 예측이나 모형에 의한 예측의 오류가 상관관계가 없거나 상관관계가 낮다는 것이다.
베이스 모델은 종종 복잡하고 다양하다. 따라서 선형 모델, 의사 결정 트리, 지원 벡터 머신, 신경망 등과 같이 예측 모델링 작업을 해결하는 
방법에 대해 매우 다른 가정을 하는 다양한 모델을 사용하는 것이 좋다. 랜덤 포리스트와 같은 다른 앙상블 알고리즘도 기본 모델로 사용될
수 있다.

기준 모델: 예측 작업에 대해 서로 다른 가정을 하는 다양한 모형을 사용한다.
메타 모델은 종종 간단하여 기본 모델에 의한 예측을 원활하게 해석할 수 있다. 따라서 선형 모형은 회귀 작업에 대한 
선형 회귀 분석(숫자 값 예측) 및 분류 작업에 대한 로지스틱 회귀 분석(클래스 레이블 예측)과 같은 메타 모델로 자주 사용된다. 
이것은 흔한 일이지만 필수는 아니다.

회귀 메타 모형: 선형 회귀 분석.
분류 메타 모형: 로지스틱 회귀 분석.
단순한 선형 모델을 메타 모델로 사용하면 종종 "블렌딩"이라는 구어를 쌓는다. 
예측에서와 같이 가중 평균 또는 기본 모델에 의한 예측의 혼합이다.

스태킹은 모델링 성능을 향상시키도록 설계되었지만 모든 경우에 개선이 보장되지는 않는다.
성능 향상을 달성하는 것은 문제의 복잡성과 교육 데이터로 충분히 잘 표현되고 예측을 결합하여 더 많은 것을 배울 수 있을 정도로 충분히
복잡한지에 따라 달라진다. 또한 기본 모형의 선택과 예측(또는 오류)에 있어 충분히 능숙하고 충분히 상관성이 없는지 여부에 따라 달라진다.
기본 모델이 적층 앙상블보다 성능이 우수하거나 우수한 경우, 복잡성이 낮기 때문에(예를 들어 설명, 훈련 및 유지 관리가 더 간단함) 
기본 모델을 대신 사용해야 한다.

mlxtend의 StackingCVRegressor를 사용하면 회귀문제에 사용할 수 있는 스태킹모델을 만들 수 있다.

참고문서:
https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/
https://techblog-history-younghunjo1.tistory.com/103
https://github.com/rasbt/mlxtend/blob/master/mlxtend/regressor/stacking_cv_regression.py