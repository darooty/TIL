{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a00fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a292cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbr(trial, X, y):\n",
    "    param = {\n",
    "        'n_estimators': 2000,\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 11),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.005, 0.01),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 100),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 100),\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    train_scores, test_scores = [], []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    model = XGBRegressor(**param)\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        tmp_X_train, tmp_X_test = X_train.iloc[train_idx, :], X_train.iloc[test_idx, :]\n",
    "        tmp_y_train, tmp_y_test = y_train[train_idx], y_train[test_idx]\n",
    "        model.fit(tmp_X_train, tmp_y_train,\n",
    "                 eval_set=[(tmp_X_test, tmp_y_test)], eval_metric=['rmse'],\n",
    "                 early_stopping_rounds=30, verbose=0,\n",
    "                 callbacks=[optuna.integration.XGBoostPruningCallback(trial, 'rmse')])\n",
    "        train_score = np.sqrt(mse(tmp_y_train, model.predict(tmp_X_train)))\n",
    "        test_score = np.sqrt(mse(tmp_y_test, model.predict(tmp_X_test)))\n",
    "        train_scores.append(train_score)\n",
    "        test_scores.append(test_score)\n",
    "    train_score = np.array(train_scores).mean()\n",
    "    test_score = np.array(test_scores).mean()\n",
    "    print(f'train score: {train_score}')\n",
    "    print(f'test score: {test_score}')\n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d0435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_lgbr = partial(objective_lgbr, X=X_train, y=y_train)\n",
    "study_lgbr = optuna.create_study(direction='minimize')\n",
    "study_lgbr.optimize(optimizer_lgbr, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_lgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194fa2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study_lgbr)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
